<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
    <head>
        <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
        <style type="text/css">
        /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
            a {
                color: #1772d0;
                text-decoration:none;
            }
            a:focus, a:hover {
                color: #f09228;
                text-decoration:none;
            }
            body,td,th {
                font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
                font-size: 16px;
                font-weight: 400
            }
            heading {
                font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
                font-size: 16px;
                font-weight: 1000
            }
            strong {
                font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
                font-size: 16px;
                font-weight: 800
            }
            strongred {
                font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
                color: 'red' ;
                font-size: 16px
            }
            section0 {
                font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
                font-size: 24px;
            }
            section1 {
                font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
                font-size: 20px;

            }      
            section2 {
                font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
                font-size: 20px;
                /* font-weight: 300 */
            }         
        </style>

        <link rel="icon" type="image/png" href="images/seal_icon.png">
        <script type="text/javascript" src="js/hidebib.js"></script>
        <title>Hao Chen</title>
        <meta name="Homepage of Hao Chen, from University of Maryland, College Park" http-equiv="Content-Type" content="Hao Chen's Homepage">
        <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
        <!-- Start : Google Analytics Code -->
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
            ga('create', 'UA-64069893-1', 'auto');
            ga('send', 'pageview');
        </script>
        <script src="js/scramble.js"></script>
    </head>

    <body>
        <table width="1000" border="0" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
                <td>
                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <p align="center"><font size="7">Hao Chen<img style="height:75px;" align="top" src="./images/L.jpeg"> </font><br>                          
                            Email: chenh@umd.edu<br>
                            <a href="https://drive.google.com/file/d/1IwJOJ_tMe3lWbO8643ZLwafpzmWA4dAj/view?usp=sharing">CV &nbsp; / &nbsp;</a>
                            <a href="https://scholar.google.com/citations?hl=en&user=1aX65skAAAAJ">Google Scholar &nbsp; / &nbsp; </a>
                            <a href="https://github.com/haochen-rye">Github &nbsp; / &nbsp;</a>
                            <a href="https://www.linkedin.com/in/hao-chen-a541b41a2/">Linkedin </a>
                            <br>
                            <a href="http://www.cs.umd.edu/">Department of Computer Science, University of Maryland</a><br>
                        </p>

                        <tr>
                            <td width="90%" valign="middle" align="justify">
                                I am currently a 4th &nbsp;Ph.D. student in the department of Computer Science at University of Maryland, College Park, 
                                advised by <a href="http://www.cs.umd.edu/~abhinav/">Prof. Abhinav Shrivastava</a>&nbsp;. 
                                I received my Master's degree in Pattern Recognition &amp; Intellegent Systems from 
                                <a href="http://english.hust.edu.cn">Huazhong University fo Science &amp; Technology (HUST)</a> with the supervison of&nbsp;<a href="https://www.researchgate.net/profile/Guoyou_Wang">Prof. Guoyou Wang</a>.
                                    <!-- At 2017, I was working closely with  <a href=http://english.siat.cas.cn/SI2017/IAIT2017/RC1/CPE_20513/Researchers1/201707/t20170724_181172.html> Prof. Yu Qiao</a> -->
                                    <!-- and  <a href=http://english.siat.cas.cn/SI2017/IAIT2017/RC1/CPE_20513/Researchers1/201707/t20170727_181385.html> Prof. Yali Wang</a>  as an intern. -->
                                    Before that, I got my bachelor's degree from the school of <a href=http://english.oei.hust.edu.cn/>Optical and Electronic Information</a> at HUST as well. <br> <br>
                                    
                                    
                                    My research interest lies in deep learning and computer vision, particularly for neural visual representation, efficient architecture design, and object detection.

                        </tr>
                    </table>



<table width="105%" align="left" border="0" cellspacing="5" cellpadding="5">

<h2>    
    <section0>
        Projects by areas: &nbsp;&nbsp;        
    </section0>
    <section1>   
        <a href="index.html" style="color:red;">  Neural Representation</a> &nbsp;&nbsp;&nbsp;
    </section1>
    <section2>   
        <a href="efficient_archi.html"> Efficent Architecture</a> &nbsp;&nbsp;&nbsp;
        <a href="object_detection.html">Object Detection</a> &nbsp;&nbsp;&nbsp;
    </section2>
    <!-- <a href="blog.html" >Blogs</a> &nbsp;&nbsp; -->
    <br>
</h2>

    <tr>
        <td width="55%" valign="top" align="center">
            <img src="https://i.imgur.com/k6OjTFi.jpg" alt="" width="100%" style="border-style: none">
            <td width="67%" valign="top">
        <heading style="color:blue;"><strong>HNeRV: Hybrid Neural Representations for Videos </strong> </heading><br>
        <strong>Under Review</a></strong> <br>
        <strong>Hao Chen</strong>, Matt Gwilliam, Ser-Nam Lim, Abhinav Shrivastava          <br><br> 
        We propose hybrid neural representation for videos, HNeRV, which can be leveraged in various visual tasks and reach comprable performance with SOTA emthods, 
        such as video compression, denoising, inpainting, restoration for unseen frames, and editing completion with few edited frames (10% etc.).        
        </td>
    </tr>

    <tr>
        <td width="55%" valign="top" align="center">
                                 <img src="./images/gnerv_teaser.png" alt="" width="100%" style="border-style: none">
                                 <td width="67%" valign="top">
           <heading style="color:blue;"><strong>GNeRV: Generalizable Neural Visual Representation with Content-adaptive Embedding </strong> </heading><br>
           <strong>Under Review</a></strong> <br>
           <strong>Hao Chen</strong>, Matt Gwilliam, Bo He, Ser-Nam Lim, Abhinav Shrivastava          <br><br> 
           We propose an image-wise neural representation, GNeRV, which combines the generalizability of autoencoders with the simplicity and compactness of implicit representation. It generalizes well on unseen images, and encodes images very fast, 36&times; faster than convolutional autoencoders.
         </td>
     </tr>

    <tr>
        <td width="55%" valign="top" align="center">
                                 <img src="./images/nerv.png" alt="" width="100%" style="border-style: none">
                                 <td width="67%" valign="top">
           <heading style="color:blue;"><strong>NeRV: Neural Representations for Videos </strong> </heading><br> 
           <strong>NeurIPS 2021 
            <a href="https://haochen-rye.github.io/NeRV">[project page]
            <a href="https://arxiv.org/abs/2110.13903">[pdf]
            </a><a href="https://github.com/haochen-rye/NeRV.git">[code]</a></strong> <br>
           <strong>Hao Chen</strong>, Bo He, Hanyu Wang, Yixuan Ren, Ser-Nam Lim, Abhinav Shrivastava           <br>
            We propose a image-wise neural representation (NeRV) to encodes videos in neural networks, 
            which takes frame index as input and outputs the corresponding RGB image. 
            NeRV shows good advantage over coordinate-based representation in decoding speed, encoding time and quality, 
            and perform well in video compression and denoising tasks.

         </td>
     </tr>



     <table width="120%" align="center" border="0" cellspacing="10" cellpadding="10">
        <h2>Acknowledge</h2>
        I appreciate everyone who  helped me or encouraged me throughout my life, especially  <a href="http://www.cs.umd.edu/~abhinav/">Prof. Abhinav Shrivastava</a>, 
        <a href="https://www.researchgate.net/profile/Guoyou_Wang">Prof. Guoyou Wang</a>, 
        <a href=http://english.siat.cas.cn/SI2017/IAIT2017/RC1/CPE_20513/Researchers1/201707/t20170724_181172.html> Prof. Yu Qiao</a>,
        <a href=http://english.siat.cas.cn/SI2017/IAIT2017/RC1/CPE_20513/Researchers1/201707/t20170727_181385.html> Prof. Yali Wang</a>,
        <a href=http://cloud.eic.hust.edu.cn:8071/~xbai/> Prof. Xiang Bai </a> 
        and all good friends I met at China and the US.

                </td>
            </tr>
        </table>
    </body>
</html